- 복습
	- MachineLearning
		- Supervised
		- Unsupervised
		- Reinforcement
			- agent가
			- environment 와 interaction
			- policy에 따라 reward를 받음
			- reward가 maximize되는 방향으로 행동

- Markov Decision Process
	- pi: state -> action으로 변환시키는 것 = agent
	
	- GridWorld
		- Agent = moving robot
		- Wall = move X
		- State = (1,1) (1,2), (1,3) 위치를 나타냄
		- Action = (North, South, West, East)
		- Reward = (+1, -1), 1번 움직일때마다 -1
		
	- Deterministic grid world
		- 결정론적 움직임
			- input -> 일관된 output
	- Stochastic grid world
		- 확률론적 움직임
			- input -> noise -> Random output

- Markov Property 
	- 정의
		- 뒷 사건과 앞 사건은 항상 독립적이여야 함
	
	- Discrete time
		- 이산적 시간
		- 컴퓨터의 작동은 이산적 시간에서
	- Continuous time
		- 연속적 시간

- Quiz3
	- 오늘 맑음
		- 내일 맑음 0.6
		- 내일 흐림 0.3
		- 내일 비 0.1
	- 오늘 비
		- 내일 맑음 0.2
		- 내일 흐림 0.5
		- 내일 비 0.3
	- 오늘 흐림
		- 내일 맑음 0.4
		- 내일 흐림 0.4
		- 내일 비 0.2
	- 1) Weather prediction model 정의
	- 2) Draw State Transition Diagram
	- 3) Construct state transition probability matrix
		- \[\[0.6, 0.3, 0.1], \[0.2, 0.5, 0.3], \[0.4, 0.4, 0.2]]
	- 4) 오늘 흐림, 내일 맑을 확률
		- 0.4 = 40%확률
	- 5) 오늘 맑음, 2일뒤 비올 확률?
		- 내일 흐림 0.3
			- 0.3 \* 0.2 = 0.06
		- 내일 비 0.1
			- 0.1 \* 0.3 = 0.03
		- 내일 맑음 0.6
			- 0.6 \* 0.3 = 0.18
		- 합 = 0.06 + 0.03 + 0.18
			- 0.27 = 27%확률