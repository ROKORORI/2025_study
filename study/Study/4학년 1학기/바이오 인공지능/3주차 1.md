- 복습
	- 다양한 바이오 데이터
		- Protein interaction network
		- Drug interaction network
		- Disease association network
		- Spatial cellular network
		- Healthcare knowledge network
		
		- 각각의 network는 서로 interaction 가능함

	- 바이오 데이터 분석의 어려움
		- 고차원성
			- 수천, 수만개의 특성
		- 노이즈 존재
			- 실험 데이터의 오차, 측정 오류
		- 데이터 부족
			- 연구 비용 문제로 데이터가 제한적
		- 비균형 데이터
			- 질병 예측 시 환자군 데이터가 적음
		
		- 바이오 데이터의 특성을 잘 이해하고, 이에 걸맞는 기계학습/딥러닝 기법을 활용해야 함
	
	- 바이오 데이터에서 ML/DL
		- 기계학습과 딥러닝을 통해
			- 대량의 데이터 자동 분석
			- 패턴 인식 및 예측 모델링
			- 전통적인 통계 분석의 한계 극복
	
- 기계학습
	- 컴퓨터가 
		- 명시적인 프로그래밍 없이 
			- 데이터에서 패턴을 학습하고 예측하는 알고리즘과 
				- 통계 모델등을 지칭하는 학문 또는 과학

- 인공지능
	- 초기
		- 인간처럼 사고/행동하는 시스템
		- 한계
			- 스스로 규칙을 찾아내지 못함
			- 수동으로 계획된 프로세스의 의한 출력
			- 방대한 데이터 처리하지 못함
	
	- 기계학습
		- 컴퓨터가 데이터를 통해 지식을 직접 학습
			- data, output -> computer -> program
		- 학습을 위해서는 다수의 데이터가 필요
	
	- 딥러닝
		- 학습 시 인공신경망 사용
		- 2012년경 기존 인공신경망 이론의 단점 극복(역전파)
		- 하드웨어의 발전으로 재등장

- 바이오 데이터에서 기계학습 활용예제
	- 유전자 발현 데이터를 활용한 질병 분류
		- 특정 유전자 발현 패턴이 암과 관련이 있는지 분류
	- 화합물의 물성/특성 예측 모델
		- 화합물의 부분 구조와 물성/특성 간 상관관계 분석
	- 단백질 서열 or 바이러스 서열 군집화
		- 서열/구조적 유사성을 바탕으로 군집을 찾고 특징을 분석

- 기계학습은 분석의 목적, 데이터 라벨의 따라 다양한 종류가 존재
	- Suervised
	- Semi-Supervised
	- Reinforcement
	- Unsupervised

- 기계학습의 데이터 준비
	- 학습/검증/테스트 데이터 준비
	
	- 전체 데이터
		- 훈련 데이터
			- 모델 학습 데이터
		- 테스트 데이터
			- 최종 성능 검사를 위해 사용하는 데이터
				- 일반화 능력 검증
					- 다른 test 데이터에 대해 검증
		- 검증 데이터
			- 모델 검증 데이터
			- 모델에 필요한 하이퍼 파라미터 결정에 사용함

	- 학습/검증/테스트 데이터와 학습 프로세스
		- parameter -> Cross Validation -> Best parameter 결정
		
	- 교차검증(Cross Validation)
		- 데이터를 여러번 훈련과 검증세트로 나누어 반복적으로 모델을 평가하는 기법
	
		- 필요성
			- 데이터의 편향 방지
			- 과적합 방지
			
			- 두가지를 종합해 일반화 성능을 평가
			
		- K-Fold 교차검증
			- 데이터를 K개의 폴드로 나눈뒤, K번 반복해서 모델을 학습하고 검증하는 방식
			- 각 폴드가 한 번씩 검증 데이터셋이 되고, 나머지 (K-1)개는 훈련 데이터로 사용됨

			- Data
				- Training data -> K개의 폴드, Test data로 나눔 
					- 이후, 최종 평가시 Test data로 이용
				- 보통 8: 1: 1로 나눔 (train, valid, test순)
		
		- Stratified K-Fold Cross Validation 
			- K-Fold의 변형으로 클래스의 비율을 동일하게 유지하면서 데이터를 나누는 방식
			- 특히 바이오 데이터(질병 데이터와 같은 불균형한 데이터셋)에서 유용
			
			- 예시
				- 암환자 100, 정상인 900
					- 일반적 K-Fold에선 테스트셋에 암환자가 없을 수 있음
					- Stratified K-Fold에선 비율을 유지함
		
		- Leave-One-Out Cross Validation(LOOCV)
			- 각 데이터 샘플을 한 번씩 테스트 데이터로 사용하고, 나머지를 훈련 데이터로 사용
			- 데이터가 N개면 N번 반복해서 학습하고 평가
			
			- 효과
				- 데이터셋이 적을 때 유용
				- 최대한 많은 데이터를 학습에 활용가능
				- 특정 데이터 샘플에 따라 성능이 달라짐
		
		- 바이오 데이터에서 활용
			- K-Fold
				- 일반적인 분석
			- Stratified K-Fold
				- 암 vs 정상 데이터 처럼 클래스 불균형이 큰 경우
			- LOOCV
				- 희귀 질병, 데이터가 매우 적은 경우

- 학습의 성능 검증 지표
	- 배경지식
		- 예측값과 실제값에 따른 Postive, Negative 구분
			
		- Postive
			- True Postive (TP)
			- False Negative (FN)
		- Negative
			- False Postive (FP)
			- True Negative (TN)
	- 지도 학습
		- 분류
			- Accuracy(정확도)
				- 전체 샘플 중 올바르게 예측한 비율
				- (TP + TN) / 전체 SET
			- Precision
				- 양성 예측이 얼마나 정확한가
					- TP / (TP + FP)
			- Recall
				- 실제 양성을 얼마나 잘 찾아냈는가
					- TP / (TP + FN)
			- F1-score
				- Precision과 Recall의 조화 평균
				- 2 \* (precision \* recall) / (precision + recall)
			
			- AUCROC
				- ROC(Receiver Operating Characteristic) Curve:
					- 모델의 TP율(Recall)과 FP율(1-특이도)의 관계를 나타내는 곡선
				- AUC(Area Under the Curve)
					- ROC 곡선 아래 면적을 계산한 값
					- 0.5 ~ 1 사이의 값을 가짐
					- 1에 가까울수록 모델 성능이 좋음
		- 회귀
			- MSE (Mean Square Error)
				- 오차 제곱 평균
			- RMSE(Root MSE)
			- MAE(Mean Absolute Error)
				- 오차 절댓값 평균
			
			- R^2
				- 결정계수
					- 모델이 데이터를 얼마나 잘 설명하는지를 나타냄
					- 1에 가까울 수록 좋음
	
	- 비지도 학습
		- 군집화의 효율성으로 성능을 평가
		
		- 실루엣 계수
			- 클러스터 내 응집도, 클러스터간 분리도 측정
			- a(i)
				- i와 cluster내 data와 거리의 평균
			- b(i)
				- i와 가장 가까운 nearest cluster centroid와의 거리
			- s(i)
				- b(i) - a(i) / max(a(i), b(i))
		
		- ARI (Adjusted Rand Index)
			- 클러스터링 결과와 실제 정답간 일치도
		
		- 차원축소
			- 고차원의 데이터를 더 작은 차원으로 변환
			- 데이터의 중요한 특징을 유지하면서도 불필요한 정보를 제거
			
			- 고차원 데이터의 문제(차원의 저주, Curse of Dimensionality)
				- 특성이 너무 많으면 모델의 성능이 저하될 수 있음
				- 데이터가 희소해지고, 계산량이 기하급수적으로 증가
				- 데이터 간 거리가 멀어져 패턴을 찾기 어려움
			
			- 차원축소 이점
				- 노이즈 제거
				- 계산 효율성 향상
				- 시각화
			
			- 재구성 오차(Reconstruction Error)
				- 차원 축소 후 복원시 원본 데이터와의 차이
			- 설명 분산 비율(Explained Variance Ratio)
				- 차원 축소 후 데이터 유지하는 정보량
					- 최대한 분산을 유지하도록 축소
					- 