- 비지도학습
	- 라벨이 없는 데이터를 사용하여 학습하는 방법으로, 데이터 내 패턴을 찾아 그룹화하거나 표현을 학습
	
	- 특징
		- 라벨 없음
			- 학습시 정답이 주어지지 않음, 모델이 자체적으로 패턴을 학습
				- 데이터 군집화
					- 데이터 내에서 유사한 패턴을 찾고 그룹으로 묶음
				- 차원 축소
					- 데이터의 주요 특성을 유지하면서 차원을 줄여 데이터의 복잡성을 낮춤
				- 이상 탐지
					- 데이터에서 일반적인 패턴과 다른 이상값을 탐지하는데 활용
					- 군집에서 멀리있는 데이터들을 탐지함.
- 클러스터링
	- k-means clustering
		- 각 클러스터의 중심을 기준으로 거리가 가까운 data를 군집화함
		- ppt 11page 참고
		
		- 가장 중요한 하이퍼 파라미터는 클러스터 개수 k임
		- K의 선택에 따라서 클러스터 성능이 천차만별임
			- K의 개수에도 영향을 받으며, 초기 위치에도 영향을 받음
		
		- K값 설정 방법
			- 엘보우 방법
				- 클러스터 개수를 다르게 설정하면서
				- 클러스터 내 오차 제곱합(WCSS)을 계산
				- WCSS가 급격히 감소하다가 완만해지는 지점(엘보우 포인트)를 최적 K로 선택함
			- 실루엣 분석
				- 데이터가 적절한 클러스터에 배정되었는지를 평가하는 지표
					- a = 다른 point와의 거리, b = 자기 자신과의 거리
					- b(i) - a(i)
					- 1에 가까울 수록 좋음
		
		- 장점
			- 단수하고 빠름
			- 해석이 쉬움
		- 단점
			- k값 결정이 어려움
			- 초기 중심 설정에 따른 결과 변동
			- 이상치에 민감
			- 비구형, 비선형 클러스터에 적절하지 못함
	
	- 계층적 군집화 알고리즘
		- 병합 (bottom up) (agglomerative)
			- 처음에는 모든 데이터 포인트가 각각 하나의 클러스터로 시작
			- 가장 가까운 클러스터들끼리 반복적으로 합쳐 나가면서 클러스터 개수를 줄임
			- 마지막에는 하나의 클러스터로 병합됨
		- 분할 (top down) (divisive)
			- 잘 사용 안됨
		
		- 주요 요소
			- 거리 측정 기준
				- 유클리디안, 맨하탄, 마할노비스 거리
					- 분포가 중요할땐 마할노비스 거리 써야함 (공분산)
					- 유클리디안, 맨하탄은 공분산 없어서 ppt case엔 거리가 비슷하게 나옴
			- 군집간 거리 기준
				- single linkage
				- complete linkage
				- average linkage
		
		- 계층적 군집화 사용
			- 덴드로그램을 통해 시각적으로 표현 가능함
			- 트리 형태의 그래프임
		
- 차원축소
	- PCA(주성분 분석)
		- 목적
			- 차원 축소
			- 데이터 시각화
			- 노이즈 제거
		
		- 과정
			- 정규화
				- 활용시엔 이것이 가장 중요함
			- 공분산 계산
			- 공분산 고유값, 고유벡터 계산
			- 주성분 선택
			- 데이터 변환
		
		- 장점
			- 고차원 데이터를 효과적으로 줄여 계산량 감소
			- 데이터의 중요 정보를 유지하면서 차원 축소 가능
			- 노이즈 제거 효과
			- 데이터 시각화 가능
			- ***PCA로 줄인 차원의 데이터를 다른 모델의 인풋으로 활용 가능
				- 가장 중요
		- 단점
			- 해석이 어려움, 변환 후 데이터의 의미가 명확하지 않음
			- 선형적인 변환만 가능
				- 복잡한 데이터 구조를 잘 표현하지 못함함
			- 정보 손실 가능성
				- PCA해석 결과값이 본래 데이터의 80 ~ 90%가 될때까지 반복
	
	- t-SNE
		- 원래 데이터의 모든점 사이의 거리를 계산
		- 가까운 점일수록 높은 확률로 연결되도록 변환함
		- 저차원 공간에서 원래의 거리 관계를 유지하도록 배치함
		- 반복적인 최적화 과정을 통해 최적의 배치를 찾음

		- 장점
			- 비선형 차원 축소 기법으로 유사한 데이터를 더 가깝게 배치하여 클러스터를 명확하게 표현
			- 데이터의 로컬 구조를 보존하는데 매우 효과적
		- 단점
			- 계산량이 많아서 느림(매우)
			- 새로운 데이터에 대한 변환이 어려움
	
	- UMAP
		- t-SNE보다 빠르고, 데이터의 전체적인 구조도 잘 보존함
		- 수학적으로는 거리 및 연결망을 활용하여 데이터의 구조를 유지하는 방식

		- 방법
			- 각 데이터 포인트의 nearest neighbor를 찾음
			- 이웃간의 연결관계를 그래프 형태로 만들고
			- 데이터의 구조를 표현함
			- 저차원 공간에서도 이 연결관계를 최대한 유지하도록 배치함
			- 반복적인 최적화 과정을 거쳐 최종적으로 차원을 축소한 결과를 얻음
			
		- 장점
			- t-sne보다 빠름
			- 고차원 데이터의 global structure를 잘 보존
			- 새로운 데이터에 대해 변환하기 쉬움
			- t-SNE보다 군집이 덜 명확하게 시각화 될 수 있음
	- 비교
		- PCA
			- 데이터 변환/압축
			- 기계학습 모델, 계산량이 중요한 경우
		- t-SNE
			- 시각화 & 군집 분석
			- 데이터 클러스터링 구조 분석, 소규모 데이터 시각화
		- UMAP
			- 시각화 & 군집 분석
			- 대규모 데이터에서도 빠른 차원 축소 & 군집 구조 유지
	
	- t-SNE와 UMAP의 주의사항
		- t-SNE
			- perplexity를 주의해야함
				- 주변 데이터를 고려하는 정도의 hyperparameter
				- 보통 30으로 잡음
		- UMAP
			- n_neighbors
				- 몇개의 이웃을 고려할지 결정
			- min_dist
				- 데이터간 최소거리

