- 비지도학습
	- 라벨이 없는 데이터를 사용하여 학습하는 방법으로, 데이터 내 패턴을 찾아 그룹화하거나 표현을 학습
	
	- 특징
		- 라벨 없음
			- 학습시 정답이 주어지지 않음, 모델이 자체적으로 패턴을 학습
				- 데이터 군집화
					- 데이터 내에서 유사한 패턴을 찾고 그룹으로 묶음
				- 차원 축소
					- 데이터의 주요 특성을 유지하면서 차원을 줄여 데이터의 복잡성을 낮춤
				- 이상 탐지
					- 데이터에서 일반적인 패턴과 다른 이상값을 탐지하는데 활용
					- 군집에서 멀리있는 데이터들을 탐지함.
- 클러스터링
	- k-means clustering
		- 각 클러스터의 중심을 기준으로 거리가 가까운 data를 군집화함
		- ppt 11page 참고
		
		- 가장 중요한 하이퍼 파라미터는 클러스터 개수 k임
		- K의 선택에 따라서 클러스터 성능이 천차만별임
			- K의 개수에도 영향을 받으며, 초기 위치에도 영향을 받음
		
		- K값 설정 방법
			- 엘보우 방법
				- 클러스터 개수를 다르게 설정하면서
				- 클러스터 내 오차 제곱합(WCSS)을 계산
				- WCSS가 급격히 감소하다가 완만해지는 지점(엘보우 포인트)를 최적 K로 선택함
			- 실루엣 분석
				- 데이터가 적절한 클러스터에 배정되었는지를 평가하는 지표
					- a = 다른 point와의 거리, b = 자기 자신과의 거리
					- b(i) - a(i)
					- 1에 가까울 수록 좋음
		
		- 장점
			- 단수하고 빠름
			- 해석이 쉬움
		- 단점
			- k값 결정이 어려움
			- 초기 중심 설정에 따른 결과 변동
			- 이상치에 민감
			- 비구형, 비선형 클러스터에 적절하지 못함
	
	- 계층적 군집화 알고리즘
		- 병합 (bottom up) (agglomerative)
			- 처음에는 모든 데이터 포인트가 각각 하나의 클러스터로 시작
			- 가장 가까운 클러스터들끼리 반복적으로 합쳐 나가면서 클러스터 개수를 줄임
			- 마지막에는 하나의 클러스터로 병합됨
		- 분할 (top down) (divisive)
			- 잘 사용 안됨
		
		- 주요 요소
			- 거리 측정 기준
				- 유클리디안, 맨하탄, 마할노비스 거리
					- 분포가 중요할땐 마할노비스 거리 써야함 (공분산)
					- 유클리디안, 맨하탄은 공분산 없어서 ppt case엔 거리가 비슷하게 나옴
			- 군집간 거리 기준
				- single linkage
				- complete linkage
				- average linkage
		
		- 계층적 군집화 사용
			- 덴드로그램을 통해 시각적으로 표현 가능함
			- 트리 형태의 그래프임
		
- 차원축소
	- PCA(주성분 분석)
		- 목적
			- 차원 축소
			- 데이터 시각화
			- 노이즈 제거
		
		- 과정
			- 정규화
				- 활용시엔 이것이 가장 중요함
			- 공분산 계산
			- 공분산 고유값, 고유벡터 계산
			- 주성분 선택
			- 데이터 변환
		
		- 장점
			- 고차원 데이터를 효과적으로 줄여 계산량 감소
			- 데이터의 중요 정보를 유지하면서 차원 축소 가능
			- 노이즈 제거 효과
			- 데이터 시각화 가능
			- ***PCA로 줄인 차원의 데이터를 다른 모델의 인풋으로 활용 가능
				- 가장 중요
		- 단점
			- 해석이 어려움, 변환 후 데이터의 의미가 명확하지 않음
			- 선형적인 변환만 가능
			- 정보 손실 가능성
				- PCA해석 결과값이 본래 데이터의 80 ~ 90%가 될때까지 반복