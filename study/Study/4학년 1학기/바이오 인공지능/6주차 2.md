- 모델 해석력과 성능의 관계
	- 일반적으로 모델의 성능과 해석력은 반비례함
	
	- 딥러닝 모델
		- 모델 성능 우수
		- 모델이 어떠한 이유로 그러한 예측을 했는지 알기 어려움
	- 오믹스 분석에서는 예측도 중요하지만 생물학적 의미해석이 중요

- 생물정보학 분석에서 해석이 중요한 이유
	- 이 유전자가 왜 중요한가?와 같은 과학적 질문에 답할 수 있어야 함
	- ai가 제시한 결과를 실험으로 검증하고, 기전 설명까지 연결해야 진짜 의미있는분석임.
	- 특히, 임상, 신약 타겟, 바이오마커 발굴 등에서는 해석 가능한 예측이 필수

- 딥러닝 모델 해석이 어려운 이유
	- 딥러닝은 다층 비선형 구조로 이루어져 있어 내부 연산 과정을 추적하기 어려움
	- latent space, embedding 등은 사람이 직관적으로 해석하기 어려운 구조
	- 특히 multi omics 모델은 다양한 오믹스 간 상호작용이 복잡하게 얽혀 있음

- 딥러닝 해석 접근법
	- 사후 해석(post-hoc)
		- 대표 기법
			- SHAP, LIME
		- 해석 대상
			- 입력 feature 중요도
	- 내재적 해석
		- 대표 기법
			- attention
		- 해석 대상
			- Embedding간 관계
	- 표현 기반 시각화
		- 대표 기법
			- UMAP, t-SNE
		- 해석 대상
			- Feature 영향도 확인
		- 해석력에선 낮음
			- 때려 맞추는 느낌 (클러스터링 결과 우수할 시 -> 좋다 판단)
	- 입력 제거 실험
		- 유전적 feature에 대해 모두 수행하여 영향력을 살펴봄
			- 단점
				- 여러번 해야함
				- 다양한 feature의 영향을 알기 위해선 매우 큰 계산이 필요
				- 따라서, 최후의 수단으로 사용됨
	
	- SHAP
		- v = model, s = feature의 집합, i = 지금 관심있는 feature
		- s개의 임의의 feature로 모델 예측, i feature과 함께 예측 
			- 높게 나옴 -> 중요도 높다
		- 수식 해석
			- s개 sampling, i번째 feature 이후 조합 구하고 평균냄
			- s! (n - (s + 1))! / n!
		- 게임 이론 기반 -> 모델과 무관하게 사용 가능
		
		- 예시
			-  Dot & Bar Plot
				- 빨강 = 유의미
				- 파랑 = 무의미
				- 예측에 크게 기여한 유전자 TOP 10을 보여줌
				- 양과 음의 상관관계를 그래프로 보여줌
				- 이후, 막대그래프로 top10 표시 (상관관계를 절댓값 취한 후 표시)
			- Force Plot
				- base value
					- sample에서 중심값을 의미
				- 개별 샘플에 대해 어떤 유전자가 예측을 증가 or 감소 시켰는지 시각화
				- 직관적인 해석이 가능
					- ex) 이 유전자가 발현이 되어 암으로 예측
				- 